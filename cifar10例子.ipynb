{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "   设置gpu显存动态分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/anaconda3/envs/keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def set_gpu_growth():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    cfg = tf.ConfigProto()\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=cfg)\n",
    "    K.set_session(session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载cifar数据集\n",
    "\n",
    "  \n",
    "   该数据集共有60000张彩色图像，这些图像是32*32，分为10个类，每类6000张图。这里面有50000张用于训练，构成了5个训练批，每一批10000张图；另外10000用于测试，单独构成一批。测试批的数据里，取自10类中的每一类，每一类随机取1000张。抽剩下的就随机排列组成了训练批。注意一个训练批中的各类图像并不一定数量相同，总的来看训练批，每一类都有5000张图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样例数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def img_show(rows,cols):\n",
    "    plt.figure(figsize=(cols*1.5,rows))\n",
    "    for i,img in enumerate(x_train[:rows*cols]):\n",
    "        plt.subplot(rows,cols,1+i)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "img_show(3,10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 只训练前8类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class=8\n",
    "# 训练数据\n",
    "indices = np.where(y_train < num_class)\n",
    "\n",
    "tx=np.take(x_train,indices[0],axis=0)\n",
    "ty=np.take(y_train, indices[0],axis=0)\n",
    "# 测试数据\n",
    "indices = np.where(y_test < num_class)\n",
    "ttx=np.take(x_test,indices[0],axis=0)\n",
    "tty=np.take(y_test, indices[0],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      "40000/40000 [==============================] - 7s 187us/step - loss: 1.4973 - acc: 0.4335 - val_loss: 1.1571 - val_acc: 0.5676\n",
      "Epoch 2/5\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.1208 - acc: 0.5887 - val_loss: 0.9708 - val_acc: 0.6446\n",
      "Epoch 3/5\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.9726 - acc: 0.6462 - val_loss: 0.8604 - val_acc: 0.6935\n",
      "Epoch 4/5\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 0.8769 - acc: 0.6857 - val_loss: 0.7983 - val_acc: 0.7127\n",
      "Epoch 5/5\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 0.8163 - acc: 0.7067 - val_loss: 0.7716 - val_acc: 0.7236\n",
      "8000/8000 [==============================] - 1s 97us/step\n",
      "Test loss: 0.7715618212223053\n",
      "Test accuracy: 0.723625\n"
     ]
    }
   ],
   "source": [
    "from cifar10_examples import get_model\n",
    "from keras.optimizers import Adam\n",
    "opt=keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model=get_model(num_class)\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(lr=0.001,decay=1e-6),\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(tx, ty,\n",
    "              batch_size=64,\n",
    "              epochs=5,\n",
    "              validation_data=(ttx, tty),\n",
    "              shuffle=True)\n",
    "scores = model.evaluate(ttx, tty, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imprinting 第9个类别，使用新模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imprint import add_new_class\n",
    "indices = np.where(y_train == 8)\n",
    "new_intput=np.take(x_train,indices[0],axis=0)\n",
    "new_model=add_new_class(model,new_intput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict.shape:(20, 9)\n",
      "预测类别:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "indices = np.where(y_test == 8)\n",
    "ttx=np.take(x_test,indices[0],axis=0)\n",
    "predict=new_model.predict(ttx[:20]) # 预测20个新类别的测试样本 \n",
    "print(\"predict.shape:{}\".format(predict.shape))\n",
    "print(\"预测类别:{}\".format(np.argmax(predict,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用原有模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict.shape:(20, 8)\n",
      "预测类别:[1 1 6 1 0 0 2 0 0 1 1 7 1 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(ttx[:20])\n",
    "print(\"predict.shape:{}\".format(predict.shape))\n",
    "print(\"预测类别:{}\".format(np.argmax(predict,axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
